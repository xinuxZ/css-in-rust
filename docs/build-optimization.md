# æ„å»ºå·¥å…·ä¼˜åŒ–æŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†ä»‹ç» CSS-in-Rust çš„æ„å»ºå·¥å…·ä¼˜åŒ–ç­–ç•¥ï¼Œå¸®åŠ©æ‚¨æå‡æ„å»ºæ€§èƒ½ã€å‡å°‘æ„å»ºæ—¶é—´å¹¶ä¼˜åŒ–è¾“å‡ºè´¨é‡ã€‚

## ğŸ“‹ æ„å»ºä¼˜åŒ–æ¦‚è§ˆ

CSS-in-Rust æä¾›å¤šå±‚æ¬¡çš„æ„å»ºä¼˜åŒ–ï¼š

- **ç¼–è¯‘æ—¶ä¼˜åŒ–** - æ­»ä»£ç æ¶ˆé™¤ã€CSS å‹ç¼©ã€é™æ€åˆ†æ
- **æ„å»ºæµç¨‹ä¼˜åŒ–** - å¢é‡ç¼–è¯‘ã€å¹¶è¡Œå¤„ç†ã€æ™ºèƒ½ç¼“å­˜
- **è¾“å‡ºä¼˜åŒ–** - æ–‡ä»¶åˆ†å‰²ã€æ‡’åŠ è½½ã€å‹ç¼©ä¼˜åŒ–
- **å¼€å‘ä½“éªŒä¼˜åŒ–** - å¿«é€Ÿé‡å»ºã€çƒ­æ›´æ–°ã€é”™è¯¯è¯Šæ–­

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åŸºç¡€æ„å»ºé…ç½®

```rust
// build.rs
use css_in_rust::build_tools::{
    CssBuildProcessor, BuildConfig, OptimizationLevel
};
use std::env;
use std::path::PathBuf;

fn main() -> Result<(), Box<dyn std::error::Error>> {
    let profile = env::var("PROFILE").unwrap_or_else(|_| "debug".to_string());
    let is_release = profile == "release";

    let config = BuildConfig {
        project_root: PathBuf::from(env::var("CARGO_MANIFEST_DIR")?),
        output_dir: PathBuf::from("target").join(&profile).join("css"),

        // åŸºç¡€ä¼˜åŒ–è®¾ç½®
        optimization_level: if is_release {
            OptimizationLevel::Aggressive
        } else {
            OptimizationLevel::Development
        },

        // å¯ç”¨å¹¶è¡Œå¤„ç†
        parallel_processing: true,
        max_parallel_jobs: num_cpus::get(),

        // å¯ç”¨ç¼“å­˜
        enable_caching: true,
        cache_dir: PathBuf::from(".cache/css-in-rust"),

        ..Default::default()
    };

    let mut processor = CssBuildProcessor::new(config)?;
    let result = processor.run()?;

    println!("æ„å»ºå®Œæˆ: å¤„ç†äº† {} ä¸ªæ–‡ä»¶", result.stats.files_processed);

    Ok(())
}
```

### 2. ä¼˜åŒ–é…ç½®æ–‡ä»¶

```toml
# css-in-rust.toml
[build]
# ä¼˜åŒ–çº§åˆ«: "development", "balanced", "aggressive"
optimization_level = "aggressive"

# å¹¶è¡Œå¤„ç†
parallel_processing = true
max_parallel_jobs = 8

# ç¼“å­˜é…ç½®
enable_caching = true
cache_strategy = "aggressive"
max_cache_size_mb = 500
cache_ttl_hours = 24

# å¢é‡ç¼–è¯‘
incremental_compilation = true
track_dependencies = true

# è¾“å‡ºä¼˜åŒ–
minify_css = true
remove_unused_css = true
generate_source_maps = false

# æ–‡ä»¶ç›‘æ§
watch_patterns = [
    "src/**/*.rs",
    "components/**/*.rs",
    "styles/**/*.css"
]

ignore_patterns = [
    "target/**",
    "**/.git/**",
    "**/node_modules/**"
]
```

## âš¡ ç¼–è¯‘æ—¶ä¼˜åŒ–

### 1. æ­»ä»£ç æ¶ˆé™¤ä¼˜åŒ–

```rust
// é…ç½®æ­»ä»£ç æ¶ˆé™¤
use css_in_rust::build_tools::{
    DeadCodeEliminationConfig, UsageAnalyzer
};

/// é…ç½®é«˜çº§æ­»ä»£ç æ¶ˆé™¤
fn configure_dead_code_elimination() -> DeadCodeEliminationConfig {
    DeadCodeEliminationConfig {
        // å¯ç”¨æ¿€è¿›æ¶ˆé™¤æ¨¡å¼
        aggressive_elimination: true,

        // ä½¿ç”¨ç‡é˜ˆå€¼ (ä½äºæ­¤å€¼çš„æ ·å¼å°†è¢«ç§»é™¤)
        usage_threshold: 0.05, // 5%

        // ä¿ç•™å…³é”®æ ·å¼
        preserve_critical_css: true,

        // åˆ†ææ·±åº¦
        analysis_depth: AnalysisDepth::Deep,

        // è·¨æ–‡ä»¶åˆ†æ
        cross_file_analysis: true,

        // åŠ¨æ€æ ·å¼æ£€æµ‹
        detect_dynamic_styles: true,

        // ä¿ç•™æ¨¡å¼
        preserve_patterns: vec![
            r"^\.(critical|important)-.*".to_string(),
            r"^\.(layout|grid|flex)-.*".to_string(),
        ],

        // æ’é™¤æ¨¡å¼
        exclude_patterns: vec![
            r"^\.(test|debug)-.*".to_string(),
        ],
    }
}

/// è‡ªå®šä¹‰ä½¿ç”¨ç‡åˆ†æå™¨
struct CustomUsageAnalyzer {
    config: DeadCodeEliminationConfig,
    usage_stats: HashMap<String, UsageStats>,
}

impl CustomUsageAnalyzer {
    /// åˆ†ææ ·å¼ä½¿ç”¨æƒ…å†µ
    pub fn analyze_usage(&mut self, source_files: &[PathBuf]) -> Result<UsageReport, AnalysisError> {
        let mut report = UsageReport::new();

        for file_path in source_files {
            let file_content = std::fs::read_to_string(file_path)?;

            // è§£æ CSS å®è°ƒç”¨
            let macro_calls = self.extract_css_macro_calls(&file_content)?;

            for macro_call in macro_calls {
                // åˆ†ææ ·å¼é€‰æ‹©å™¨
                let selectors = self.parse_selectors(&macro_call.css_content)?;

                // è®°å½•ä½¿ç”¨æƒ…å†µ
                for selector in selectors {
                    self.record_usage(&selector, file_path, macro_call.line_number);
                }
            }
        }

        // ç”Ÿæˆä½¿ç”¨æŠ¥å‘Š
        self.generate_usage_report()
    }

    /// æå– CSS å®è°ƒç”¨
    fn extract_css_macro_calls(&self, content: &str) -> Result<Vec<CssMacroCall>, ParseError> {
        let mut calls = Vec::new();

        // ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… css! å®
        let css_macro_regex = regex::Regex::new(r"css!\s*\{([^}]+)\}")?;

        for (line_num, line) in content.lines().enumerate() {
            if let Some(captures) = css_macro_regex.captures(line) {
                if let Some(css_content) = captures.get(1) {
                    calls.push(CssMacroCall {
                        line_number: line_num + 1,
                        css_content: css_content.as_str().to_string(),
                        file_path: PathBuf::new(), // å°†åœ¨è°ƒç”¨å¤„è®¾ç½®
                    });
                }
            }
        }

        Ok(calls)
    }

    /// è§£æ CSS é€‰æ‹©å™¨
    fn parse_selectors(&self, css_content: &str) -> Result<Vec<CssSelector>, ParseError> {
        let mut selectors = Vec::new();

        // è§£æç±»é€‰æ‹©å™¨
        let class_regex = regex::Regex::new(r"\.([a-zA-Z][a-zA-Z0-9_-]*)")?;
        for captures in class_regex.captures_iter(css_content) {
            if let Some(class_name) = captures.get(1) {
                selectors.push(CssSelector {
                    selector_type: SelectorType::Class,
                    name: class_name.as_str().to_string(),
                    specificity: calculate_specificity(&format!(".{}", class_name.as_str())),
                });
            }
        }

        // è§£æ ID é€‰æ‹©å™¨
        let id_regex = regex::Regex::new(r"#([a-zA-Z][a-zA-Z0-9_-]*)")?;
        for captures in id_regex.captures_iter(css_content) {
            if let Some(id_name) = captures.get(1) {
                selectors.push(CssSelector {
                    selector_type: SelectorType::Id,
                    name: id_name.as_str().to_string(),
                    specificity: calculate_specificity(&format!("#{}", id_name.as_str())),
                });
            }
        }

        Ok(selectors)
    }

    /// è®°å½•æ ·å¼ä½¿ç”¨æƒ…å†µ
    fn record_usage(&mut self, selector: &CssSelector, file_path: &PathBuf, line_number: usize) {
        let key = format!("{}:{}", selector.selector_type.as_str(), selector.name);

        let stats = self.usage_stats.entry(key).or_insert_with(|| UsageStats {
            selector: selector.clone(),
            usage_count: 0,
            files: HashSet::new(),
            first_seen: std::time::SystemTime::now(),
            last_seen: std::time::SystemTime::now(),
        });

        stats.usage_count += 1;
        stats.files.insert(file_path.clone());
        stats.last_seen = std::time::SystemTime::now();
    }
}

/// è®¡ç®— CSS é€‰æ‹©å™¨ç‰¹å¼‚æ€§
fn calculate_specificity(selector: &str) -> u32 {
    let mut specificity = 0;

    // ID é€‰æ‹©å™¨æƒé‡: 100
    specificity += selector.matches('#').count() as u32 * 100;

    // ç±»é€‰æ‹©å™¨æƒé‡: 10
    specificity += selector.matches('.').count() as u32 * 10;

    // å…ƒç´ é€‰æ‹©å™¨æƒé‡: 1
    let element_count = selector.split_whitespace()
        .filter(|s| !s.starts_with('.') && !s.starts_with('#'))
        .count();
    specificity += element_count as u32;

    specificity
}
```

### 2. CSS å‹ç¼©ä¼˜åŒ–

```rust
// CSS å‹ç¼©é…ç½®
use css_in_rust::build_tools::{
    CssMinifier, MinificationConfig, CompressionLevel
};

/// é…ç½® CSS å‹ç¼©
fn configure_css_minification() -> MinificationConfig {
    MinificationConfig {
        // å‹ç¼©çº§åˆ«
        compression_level: CompressionLevel::Maximum,

        // ç§»é™¤æ³¨é‡Š
        remove_comments: true,

        // ç§»é™¤ç©ºç™½å­—ç¬¦
        remove_whitespace: true,

        // åˆå¹¶ç›¸åŒè§„åˆ™
        merge_duplicate_rules: true,

        // ä¼˜åŒ–é€‰æ‹©å™¨
        optimize_selectors: true,

        // ç®€åŒ–é¢œè‰²å€¼
        simplify_colors: true,

        // å‹ç¼©æ•°å€¼
        compress_numbers: true,

        // ç§»é™¤æœªä½¿ç”¨çš„å‰ç¼€
        remove_unused_prefixes: true,

        // ä¿ç•™é‡è¦æ³¨é‡Š
        preserve_important_comments: true,

        // è‡ªå®šä¹‰ä¼˜åŒ–è§„åˆ™
        custom_optimizations: vec![
            OptimizationRule::RemoveEmptyRules,
            OptimizationRule::MergeMediaQueries,
            OptimizationRule::OptimizeKeyframes,
        ],
    }
}

/// è‡ªå®šä¹‰ CSS å‹ç¼©å™¨
struct AdvancedCssMinifier {
    config: MinificationConfig,
    optimization_stats: OptimizationStats,
}

impl AdvancedCssMinifier {
    /// å‹ç¼© CSS å†…å®¹
    pub fn minify(&mut self, css_content: &str) -> Result<MinificationResult, MinificationError> {
        let start_time = std::time::Instant::now();
        let original_size = css_content.len();

        let mut result = css_content.to_string();

        // åº”ç”¨å„ç§ä¼˜åŒ–
        result = self.remove_comments(&result)?;
        result = self.remove_whitespace(&result)?;
        result = self.merge_duplicate_rules(&result)?;
        result = self.optimize_selectors(&result)?;
        result = self.simplify_colors(&result)?;
        result = self.compress_numbers(&result)?;
        result = self.apply_custom_optimizations(&result)?;

        let final_size = result.len();
        let compression_ratio = (original_size - final_size) as f64 / original_size as f64;

        // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.optimization_stats.total_files += 1;
        self.optimization_stats.total_original_size += original_size;
        self.optimization_stats.total_compressed_size += final_size;
        self.optimization_stats.total_time += start_time.elapsed();

        Ok(MinificationResult {
            minified_css: result,
            original_size,
            compressed_size: final_size,
            compression_ratio,
            optimizations_applied: self.get_applied_optimizations(),
            processing_time: start_time.elapsed(),
        })
    }

    /// ç§»é™¤æ³¨é‡Š
    fn remove_comments(&self, css: &str) -> Result<String, MinificationError> {
        if !self.config.remove_comments {
            return Ok(css.to_string());
        }

        let comment_regex = regex::Regex::new(r"/\*[^*]*\*+(?:[^/*][^*]*\*+)*/")?;

        let mut result = css.to_string();

        // ä¿ç•™é‡è¦æ³¨é‡Š (ä»¥ /*! å¼€å¤´)
        if self.config.preserve_important_comments {
            let important_comment_regex = regex::Regex::new(r"/\*![^*]*\*+(?:[^/*][^*]*\*+)*/")?;
            let important_comments: Vec<_> = important_comment_regex
                .find_iter(&result)
                .map(|m| m.as_str().to_string())
                .collect();

            // ç§»é™¤æ‰€æœ‰æ³¨é‡Š
            result = comment_regex.replace_all(&result, "").to_string();

            // é‡æ–°æ·»åŠ é‡è¦æ³¨é‡Š
            for comment in important_comments {
                result = format!("{} {}", comment, result);
            }
        } else {
            result = comment_regex.replace_all(&result, "").to_string();
        }

        Ok(result)
    }

    /// ç§»é™¤ç©ºç™½å­—ç¬¦
    fn remove_whitespace(&self, css: &str) -> Result<String, MinificationError> {
        if !self.config.remove_whitespace {
            return Ok(css.to_string());
        }

        let mut result = css.to_string();

        // ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        result = regex::Regex::new(r"\s+")?.replace_all(&result, " ").to_string();

        // ç§»é™¤é€‰æ‹©å™¨å‘¨å›´çš„ç©ºç™½
        result = regex::Regex::new(r"\s*\{\s*")?.replace_all(&result, "{").to_string();
        result = regex::Regex::new(r"\s*\}\s*")?.replace_all(&result, "}").to_string();

        // ç§»é™¤å±æ€§å‘¨å›´çš„ç©ºç™½
        result = regex::Regex::new(r"\s*:\s*")?.replace_all(&result, ":").to_string();
        result = regex::Regex::new(r"\s*;\s*")?.replace_all(&result, ";").to_string();

        // ç§»é™¤é€—å·å‘¨å›´çš„ç©ºç™½
        result = regex::Regex::new(r"\s*,\s*")?.replace_all(&result, ",").to_string();

        Ok(result.trim().to_string())
    }

    /// åˆå¹¶é‡å¤è§„åˆ™
    fn merge_duplicate_rules(&self, css: &str) -> Result<String, MinificationError> {
        if !self.config.merge_duplicate_rules {
            return Ok(css.to_string());
        }

        // è§£æ CSS è§„åˆ™
        let rules = self.parse_css_rules(css)?;

        // æŒ‰é€‰æ‹©å™¨åˆ†ç»„
        let mut grouped_rules: HashMap<String, Vec<CssProperty>> = HashMap::new();

        for rule in rules {
            let selector_key = rule.selectors.join(",");
            grouped_rules.entry(selector_key)
                .or_insert_with(Vec::new)
                .extend(rule.properties);
        }

        // é‡æ–°æ„å»º CSS
        let mut result = String::new();
        for (selectors, properties) in grouped_rules {
            result.push_str(&selectors);
            result.push('{');

            for property in properties {
                result.push_str(&format!("{}:{}", property.name, property.value));
                if property.important {
                    result.push_str("!important");
                }
                result.push(';');
            }

            result.push('}');
        }

        Ok(result)
    }
}
```

## ğŸ”„ æ„å»ºæµç¨‹ä¼˜åŒ–

### 1. å¢é‡ç¼–è¯‘é…ç½®

```rust
// å¢é‡ç¼–è¯‘ç®¡ç†å™¨
use css_in_rust::build_tools::{
    IncrementalCompiler, DependencyTracker, BuildCache
};
use std::collections::{HashMap, HashSet};
use std::path::PathBuf;
use std::time::SystemTime;

/// å¢é‡ç¼–è¯‘ç®¡ç†å™¨
pub struct IncrementalBuildManager {
    dependency_tracker: DependencyTracker,
    build_cache: BuildCache,
    last_build_time: Option<SystemTime>,
    file_checksums: HashMap<PathBuf, String>,
}

impl IncrementalBuildManager {
    /// åˆ›å»ºæ–°çš„å¢é‡ç¼–è¯‘ç®¡ç†å™¨
    pub fn new(cache_dir: PathBuf) -> Result<Self, BuildError> {
        Ok(Self {
            dependency_tracker: DependencyTracker::new(),
            build_cache: BuildCache::new(cache_dir)?,
            last_build_time: None,
            file_checksums: HashMap::new(),
        })
    }

    /// æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°ç¼–è¯‘
    pub fn needs_rebuild(&mut self, source_files: &[PathBuf]) -> Result<bool, BuildError> {
        // æ£€æŸ¥æ˜¯å¦æ˜¯é¦–æ¬¡æ„å»º
        if self.last_build_time.is_none() {
            return Ok(true);
        }

        let last_build = self.last_build_time.unwrap();

        // æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦æœ‰å˜åŒ–
        for file_path in source_files {
            let metadata = std::fs::metadata(file_path)?;
            let modified_time = metadata.modified()?;

            if modified_time > last_build {
                return Ok(true);
            }

            // æ£€æŸ¥æ–‡ä»¶å†…å®¹æ˜¯å¦æœ‰å˜åŒ–
            let current_checksum = self.calculate_file_checksum(file_path)?;
            if let Some(cached_checksum) = self.file_checksums.get(file_path) {
                if current_checksum != *cached_checksum {
                    return Ok(true);
                }
            } else {
                return Ok(true);
            }
        }

        // æ£€æŸ¥ä¾èµ–æ–‡ä»¶æ˜¯å¦æœ‰å˜åŒ–
        let dependencies = self.dependency_tracker.get_all_dependencies();
        for dep_path in dependencies {
            if dep_path.exists() {
                let metadata = std::fs::metadata(&dep_path)?;
                let modified_time = metadata.modified()?;

                if modified_time > last_build {
                    return Ok(true);
                }
            }
        }

        Ok(false)
    }

    /// æ‰§è¡Œå¢é‡æ„å»º
    pub fn incremental_build(
        &mut self,
        source_files: &[PathBuf],
        config: &BuildConfig,
    ) -> Result<IncrementalBuildResult, BuildError> {
        let start_time = std::time::Instant::now();

        // åˆ†æå˜æ›´çš„æ–‡ä»¶
        let changed_files = self.analyze_changed_files(source_files)?;

        // è®¡ç®—å—å½±å“çš„æ–‡ä»¶
        let affected_files = self.dependency_tracker
            .get_affected_files(&changed_files)?;

        // ä»ç¼“å­˜ä¸­åŠ è½½æœªå˜æ›´çš„æ–‡ä»¶
        let mut cached_results = HashMap::new();
        for file_path in source_files {
            if !affected_files.contains(file_path) {
                if let Some(cached_result) = self.build_cache.get(file_path)? {
                    cached_results.insert(file_path.clone(), cached_result);
                }
            }
        }

        // åªç¼–è¯‘å—å½±å“çš„æ–‡ä»¶
        let mut compilation_results = HashMap::new();
        for file_path in &affected_files {
            let result = self.compile_single_file(file_path, config)?;
            compilation_results.insert(file_path.clone(), result.clone());

            // æ›´æ–°ç¼“å­˜
            self.build_cache.set(file_path, &result)?;

            // æ›´æ–°æ–‡ä»¶æ ¡éªŒå’Œ
            let checksum = self.calculate_file_checksum(file_path)?;
            self.file_checksums.insert(file_path.clone(), checksum);
        }

        // åˆå¹¶ç»“æœ
        let mut all_results = cached_results;
        all_results.extend(compilation_results);

        // æ›´æ–°æ„å»ºæ—¶é—´
        self.last_build_time = Some(SystemTime::now());

        Ok(IncrementalBuildResult {
            compiled_files: affected_files,
            cached_files: source_files.iter()
                .filter(|f| !affected_files.contains(f))
                .cloned()
                .collect(),
            total_files: source_files.len(),
            build_time: start_time.elapsed(),
            cache_hit_ratio: (source_files.len() - affected_files.len()) as f64 / source_files.len() as f64,
            results: all_results,
        })
    }

    /// åˆ†æå˜æ›´çš„æ–‡ä»¶
    fn analyze_changed_files(&mut self, source_files: &[PathBuf]) -> Result<HashSet<PathBuf>, BuildError> {
        let mut changed_files = HashSet::new();

        for file_path in source_files {
            let current_checksum = self.calculate_file_checksum(file_path)?;

            if let Some(cached_checksum) = self.file_checksums.get(file_path) {
                if current_checksum != *cached_checksum {
                    changed_files.insert(file_path.clone());
                }
            } else {
                // æ–°æ–‡ä»¶
                changed_files.insert(file_path.clone());
            }
        }

        Ok(changed_files)
    }

    /// è®¡ç®—æ–‡ä»¶æ ¡éªŒå’Œ
    fn calculate_file_checksum(&self, file_path: &PathBuf) -> Result<String, BuildError> {
        use sha2::{Sha256, Digest};

        let content = std::fs::read(file_path)?;
        let mut hasher = Sha256::new();
        hasher.update(&content);
        let result = hasher.finalize();

        Ok(format!("{:x}", result))
    }

    /// ç¼–è¯‘å•ä¸ªæ–‡ä»¶
    fn compile_single_file(
        &self,
        file_path: &PathBuf,
        config: &BuildConfig,
    ) -> Result<CompilationResult, BuildError> {
        // è¯»å–æ–‡ä»¶å†…å®¹
        let content = std::fs::read_to_string(file_path)?;

        // è§£æ CSS å®
        let css_macros = self.extract_css_macros(&content)?;

        // ç¼–è¯‘ CSS
        let mut compiled_css = String::new();
        for css_macro in css_macros {
            let processed_css = self.process_css_macro(&css_macro, config)?;
            compiled_css.push_str(&processed_css);
        }

        // åº”ç”¨ä¼˜åŒ–
        let optimized_css = if config.optimization_level != OptimizationLevel::None {
            self.optimize_css(&compiled_css, config)?
        } else {
            compiled_css
        };

        Ok(CompilationResult {
            file_path: file_path.clone(),
            original_content: content,
            compiled_css: optimized_css,
            compilation_time: std::time::Instant::now().elapsed(),
            optimizations_applied: vec![], // æ ¹æ®å®é™…ä¼˜åŒ–å¡«å……
        })
    }
}
```

### 2. å¹¶è¡Œå¤„ç†ä¼˜åŒ–

```rust
// å¹¶è¡Œæ„å»ºå¤„ç†å™¨
use rayon::prelude::*;
use std::sync::{Arc, Mutex};
use std::collections::HashMap;

/// å¹¶è¡Œæ„å»ºå¤„ç†å™¨
pub struct ParallelBuildProcessor {
    max_parallel_jobs: usize,
    build_stats: Arc<Mutex<ParallelBuildStats>>,
}

impl ParallelBuildProcessor {
    /// åˆ›å»ºæ–°çš„å¹¶è¡Œæ„å»ºå¤„ç†å™¨
    pub fn new(max_parallel_jobs: Option<usize>) -> Self {
        let jobs = max_parallel_jobs.unwrap_or_else(num_cpus::get);

        Self {
            max_parallel_jobs: jobs,
            build_stats: Arc::new(Mutex::new(ParallelBuildStats::new())),
        }
    }

    /// å¹¶è¡Œå¤„ç†æ–‡ä»¶
    pub fn process_files_parallel(
        &self,
        files: &[PathBuf],
        config: &BuildConfig,
    ) -> Result<ParallelBuildResult, BuildError> {
        let start_time = std::time::Instant::now();

        // é…ç½® Rayon çº¿ç¨‹æ± 
        let pool = rayon::ThreadPoolBuilder::new()
            .num_threads(self.max_parallel_jobs)
            .build()
            .map_err(|e| BuildError::ThreadPoolError(e.to_string()))?;

        // å¹¶è¡Œå¤„ç†æ–‡ä»¶
        let results: Result<Vec<_>, _> = pool.install(|| {
            files.par_iter()
                .map(|file_path| {
                    let file_start = std::time::Instant::now();

                    // å¤„ç†å•ä¸ªæ–‡ä»¶
                    let result = self.process_single_file(file_path, config);

                    // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                    {
                        let mut stats = self.build_stats.lock().unwrap();
                        stats.files_processed += 1;
                        stats.total_processing_time += file_start.elapsed();

                        if result.is_ok() {
                            stats.successful_files += 1;
                        } else {
                            stats.failed_files += 1;
                        }
                    }

                    result
                })
                .collect()
        });

        let file_results = results?;
        let total_time = start_time.elapsed();

        // åˆå¹¶ç»“æœ
        let mut combined_css = String::new();
        let mut total_original_size = 0;
        let mut total_compressed_size = 0;

        for result in &file_results {
            combined_css.push_str(&result.compiled_css);
            total_original_size += result.original_size;
            total_compressed_size += result.compressed_size;
        }

        // è®¡ç®—å¹¶è¡Œæ•ˆç‡
        let stats = self.build_stats.lock().unwrap();
        let parallel_efficiency = if total_time.as_millis() > 0 {
            stats.total_processing_time.as_millis() as f64 /
            (total_time.as_millis() as f64 * self.max_parallel_jobs as f64)
        } else {
            0.0
        };

        Ok(ParallelBuildResult {
            file_results,
            combined_css,
            total_files: files.len(),
            successful_files: stats.successful_files,
            failed_files: stats.failed_files,
            total_time,
            parallel_efficiency,
            threads_used: self.max_parallel_jobs,
            total_original_size,
            total_compressed_size,
        })
    }

    /// å¤„ç†å•ä¸ªæ–‡ä»¶
    fn process_single_file(
        &self,
        file_path: &PathBuf,
        config: &BuildConfig,
    ) -> Result<FileProcessingResult, BuildError> {
        let start_time = std::time::Instant::now();

        // è¯»å–æ–‡ä»¶
        let content = std::fs::read_to_string(file_path)
            .map_err(|e| BuildError::FileReadError(file_path.clone(), e.to_string()))?;

        let original_size = content.len();

        // æå–å’Œå¤„ç† CSS
        let css_content = self.extract_and_process_css(&content, config)?;

        // åº”ç”¨ä¼˜åŒ–
        let optimized_css = if config.enable_optimization {
            self.optimize_css(&css_content, config)?
        } else {
            css_content
        };

        let compressed_size = optimized_css.len();
        let processing_time = start_time.elapsed();

        Ok(FileProcessingResult {
            file_path: file_path.clone(),
            compiled_css: optimized_css,
            original_size,
            compressed_size,
            processing_time,
            thread_id: rayon::current_thread_index().unwrap_or(0),
        })
    }

    /// æå–å’Œå¤„ç† CSS
    fn extract_and_process_css(
        &self,
        content: &str,
        config: &BuildConfig,
    ) -> Result<String, BuildError> {
        // CSS å®æå–é€»è¾‘
        let css_macro_regex = regex::Regex::new(r"css!\s*\{([^}]+)\}")
            .map_err(|e| BuildError::RegexError(e.to_string()))?;

        let mut processed_css = String::new();

        for captures in css_macro_regex.captures_iter(content) {
            if let Some(css_match) = captures.get(1) {
                let css_content = css_match.as_str();

                // å¤„ç† CSS å†…å®¹
                let processed = self.process_css_content(css_content, config)?;
                processed_css.push_str(&processed);
                processed_css.push('\n');
            }
        }

        Ok(processed_css)
    }

    /// å¤„ç† CSS å†…å®¹
    fn process_css_content(
        &self,
        css_content: &str,
        config: &BuildConfig,
    ) -> Result<String, BuildError> {
        let mut result = css_content.to_string();

        // åº”ç”¨é¢„å¤„ç†å™¨
        if config.enable_preprocessing {
            result = self.apply_preprocessing(&result)?;
        }

        // åº”ç”¨å˜é‡æ›¿æ¢
        if config.enable_variables {
            result = self.apply_variable_substitution(&result)?;
        }

        // åº”ç”¨è‡ªåŠ¨å‰ç¼€
        if config.enable_autoprefixer {
            result = self.apply_autoprefixer(&result)?;
        }

        Ok(result)
    }
}

/// å¹¶è¡Œæ„å»ºç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct ParallelBuildStats {
    pub files_processed: usize,
    pub successful_files: usize,
    pub failed_files: usize,
    pub total_processing_time: std::time::Duration,
}

impl ParallelBuildStats {
    pub fn new() -> Self {
        Self {
            files_processed: 0,
            successful_files: 0,
            failed_files: 0,
            total_processing_time: std::time::Duration::new(0, 0),
        }
    }
}
```

## ğŸ’¾ ç¼“å­˜ä¼˜åŒ–ç­–ç•¥

### 1. æ™ºèƒ½ç¼“å­˜ç®¡ç†

```rust
// æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨
use serde::{Serialize, Deserialize};
use std::collections::HashMap;
use std::path::PathBuf;
use std::time::{SystemTime, Duration};

/// æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨
pub struct SmartCacheManager {
    cache_dir: PathBuf,
    cache_strategy: CacheStrategy,
    max_cache_size: usize,
    ttl: Duration,
    cache_index: CacheIndex,
}

/// ç¼“å­˜ç­–ç•¥
#[derive(Debug, Clone)]
pub enum CacheStrategy {
    /// ä¿å®ˆç­–ç•¥ - åªç¼“å­˜ç¨³å®šçš„ç»“æœ
    Conservative,
    /// å¹³è¡¡ç­–ç•¥ - ç¼“å­˜å¤§éƒ¨åˆ†ç»“æœ
    Balanced,
    /// æ¿€è¿›ç­–ç•¥ - ç¼“å­˜æ‰€æœ‰å¯èƒ½çš„ç»“æœ
    Aggressive,
}

/// ç¼“å­˜ç´¢å¼•
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CacheIndex {
    entries: HashMap<String, CacheEntry>,
    total_size: usize,
    last_cleanup: SystemTime,
}

/// ç¼“å­˜æ¡ç›®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CacheEntry {
    key: String,
    file_path: PathBuf,
    content_hash: String,
    result_hash: String,
    size: usize,
    created_at: SystemTime,
    last_accessed: SystemTime,
    access_count: u32,
    dependencies: Vec<PathBuf>,
}

impl SmartCacheManager {
    /// åˆ›å»ºæ–°çš„ç¼“å­˜ç®¡ç†å™¨
    pub fn new(
        cache_dir: PathBuf,
        strategy: CacheStrategy,
        max_size_mb: usize,
        ttl_hours: u64,
    ) -> Result<Self, CacheError> {
        let cache_index = Self::load_or_create_index(&cache_dir)?;

        Ok(Self {
            cache_dir,
            cache_strategy: strategy,
            max_cache_size: max_size_mb * 1024 * 1024, // è½¬æ¢ä¸ºå­—èŠ‚
            ttl: Duration::from_secs(ttl_hours * 3600),
            cache_index,
        })
    }

    /// è·å–ç¼“å­˜ç»“æœ
    pub fn get(&mut self, key: &str, dependencies: &[PathBuf]) -> Result<Option<CachedResult>, CacheError> {
        // æ£€æŸ¥ç¼“å­˜æ¡ç›®æ˜¯å¦å­˜åœ¨
        if let Some(entry) = self.cache_index.entries.get_mut(key) {
            // æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if self.is_expired(entry) {
                self.remove_entry(key)?;
                return Ok(None);
            }

            // æ£€æŸ¥ä¾èµ–æ˜¯å¦æœ‰å˜åŒ–
            if self.dependencies_changed(entry, dependencies)? {
                self.remove_entry(key)?;
                return Ok(None);
            }

            // æ›´æ–°è®¿é—®ä¿¡æ¯
            entry.last_accessed = SystemTime::now();
            entry.access_count += 1;

            // åŠ è½½ç¼“å­˜ç»“æœ
            let result = self.load_cached_result(entry)?;
            return Ok(Some(result));
        }

        Ok(None)
    }

    /// è®¾ç½®ç¼“å­˜ç»“æœ
    pub fn set(
        &mut self,
        key: &str,
        file_path: &PathBuf,
        content_hash: &str,
        result: &CachedResult,
        dependencies: &[PathBuf],
    ) -> Result<(), CacheError> {
        // æ£€æŸ¥ç¼“å­˜ç­–ç•¥
        if !self.should_cache(result) {
            return Ok(());
        }

        // åºåˆ—åŒ–ç»“æœ
        let serialized = bincode::serialize(result)
            .map_err(|e| CacheError::SerializationError(e.to_string()))?;

        let result_size = serialized.len();

        // æ£€æŸ¥ç¼“å­˜ç©ºé—´
        self.ensure_cache_space(result_size)?;

        // åˆ›å»ºç¼“å­˜æ–‡ä»¶
        let cache_file_path = self.cache_dir.join(format!("{}.cache", key));
        std::fs::write(&cache_file_path, &serialized)
            .map_err(|e| CacheError::WriteError(cache_file_path.clone(), e.to_string()))?;

        // åˆ›å»ºç¼“å­˜æ¡ç›®
        let entry = CacheEntry {
            key: key.to_string(),
            file_path: file_path.clone(),
            content_hash: content_hash.to_string(),
            result_hash: self.calculate_result_hash(&serialized),
            size: result_size,
            created_at: SystemTime::now(),
            last_accessed: SystemTime::now(),
            access_count: 1,
            dependencies: dependencies.to_vec(),
        };

        // æ›´æ–°ç´¢å¼•
        self.cache_index.entries.insert(key.to_string(), entry);
        self.cache_index.total_size += result_size;

        // ä¿å­˜ç´¢å¼•
        self.save_index()?;

        Ok(())
    }

    /// æ£€æŸ¥æ˜¯å¦åº”è¯¥ç¼“å­˜
    fn should_cache(&self, result: &CachedResult) -> bool {
        match self.cache_strategy {
            CacheStrategy::Conservative => {
                // åªç¼“å­˜å¤§æ–‡ä»¶æˆ–å¤æ‚å¤„ç†ç»“æœ
                result.processing_time.as_millis() > 100 || result.original_size > 10240
            }
            CacheStrategy::Balanced => {
                // ç¼“å­˜å¤§éƒ¨åˆ†ç»“æœï¼Œé™¤äº†éå¸¸å°çš„æ–‡ä»¶
                result.original_size > 1024
            }
            CacheStrategy::Aggressive => {
                // ç¼“å­˜æ‰€æœ‰ç»“æœ
                true
            }
        }
    }

    /// ç¡®ä¿ç¼“å­˜ç©ºé—´
    fn ensure_cache_space(&mut self, required_size: usize) -> Result<(), CacheError> {
        // æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†
        if self.cache_index.total_size + required_size > self.max_cache_size {
            self.cleanup_cache(required_size)?;
        }

        Ok(())
    }

    /// æ¸…ç†ç¼“å­˜
    fn cleanup_cache(&mut self, required_size: usize) -> Result<(), CacheError> {
        let mut entries_to_remove = Vec::new();
        let target_size = self.max_cache_size - required_size;

        // æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆLRU + è®¿é—®é¢‘ç‡ï¼‰
        let mut sorted_entries: Vec<_> = self.cache_index.entries.iter().collect();
        sorted_entries.sort_by(|a, b| {
            let score_a = self.calculate_cache_score(a.1);
            let score_b = self.calculate_cache_score(b.1);
            score_a.partial_cmp(&score_b).unwrap_or(std::cmp::Ordering::Equal)
        });

        // ç§»é™¤ä½ä¼˜å…ˆçº§æ¡ç›®
        let mut current_size = self.cache_index.total_size;
        for (key, entry) in sorted_entries {
            if current_size <= target_size {
                break;
            }

            entries_to_remove.push(key.clone());
            current_size -= entry.size;
        }

        // æ‰§è¡Œç§»é™¤
        for key in entries_to_remove {
            self.remove_entry(&key)?;
        }

        Ok(())
    }

    /// è®¡ç®—ç¼“å­˜åˆ†æ•°ï¼ˆç”¨äº LRU ç®—æ³•ï¼‰
    fn calculate_cache_score(&self, entry: &CacheEntry) -> f64 {
        let now = SystemTime::now();

        // æ—¶é—´å› å­ï¼ˆè¶Šä¹…æœªè®¿é—®åˆ†æ•°è¶Šä½ï¼‰
        let time_factor = if let Ok(duration) = now.duration_since(entry.last_accessed) {
            1.0 / (duration.as_secs() as f64 + 1.0)
        } else {
            0.0
        };

        // è®¿é—®é¢‘ç‡å› å­
        let frequency_factor = entry.access_count as f64;

        // å¤§å°å› å­ï¼ˆå¤§æ–‡ä»¶ä¼˜å…ˆä¿ç•™ï¼‰
        let size_factor = (entry.size as f64).log10();

        // ç»¼åˆåˆ†æ•°
        time_factor * 0.4 + frequency_factor * 0.4 + size_factor * 0.2
    }

    /// æ£€æŸ¥ä¾èµ–æ˜¯å¦æœ‰å˜åŒ–
    fn dependencies_changed(&self, entry: &CacheEntry, current_deps: &[PathBuf]) -> Result<bool, CacheError> {
        // æ£€æŸ¥ä¾èµ–æ•°é‡æ˜¯å¦å˜åŒ–
        if entry.dependencies.len() != current_deps.len() {
            return Ok(true);
        }

        // æ£€æŸ¥æ¯ä¸ªä¾èµ–æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´
        for dep_path in &entry.dependencies {
            if dep_path.exists() {
                let metadata = std::fs::metadata(dep_path)
                    .map_err(|e| CacheError::FileError(dep_path.clone(), e.to_string()))?;

                let modified_time = metadata.modified()
                    .map_err(|e| CacheError::FileError(dep_path.clone(), e.to_string()))?;

                if modified_time > entry.created_at {
                    return Ok(true);
                }
            } else {
                // ä¾èµ–æ–‡ä»¶è¢«åˆ é™¤
                return Ok(true);
            }
        }

        Ok(false)
    }
}
```

## ğŸ“Š æ„å»ºæ€§èƒ½ç›‘æ§

### 1. æ€§èƒ½æŒ‡æ ‡æ”¶é›†

```rust
// æ„å»ºæ€§èƒ½ç›‘æ§å™¨
use std::time::{Instant, Duration};
use std::collections::HashMap;
use serde::{Serialize, Deserialize};

/// æ„å»ºæ€§èƒ½ç›‘æ§å™¨
pub struct BuildPerformanceMonitor {
    metrics: BuildMetrics,
    phase_timers: HashMap<String, Instant>,
    enabled: bool,
}

/// æ„å»ºæŒ‡æ ‡
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BuildMetrics {
    pub total_build_time: Duration,
    pub compilation_time: Duration,
    pub optimization_time: Duration,
    pub io_time: Duration,
    pub cache_time: Duration,

    pub files_processed: usize,
    pub total_input_size: usize,
    pub total_output_size: usize,
    pub compression_ratio: f64,

    pub cache_hits: usize,
    pub cache_misses: usize,
    pub cache_hit_ratio: f64,

    pub parallel_efficiency: f64,
    pub threads_used: usize,

    pub phase_timings: HashMap<String, Duration>,
    pub file_timings: HashMap<String, Duration>,

    pub memory_usage: MemoryMetrics,
    pub error_count: usize,
    pub warning_count: usize,
}

/// å†…å­˜ä½¿ç”¨æŒ‡æ ‡
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MemoryMetrics {
    pub peak_memory_usage: usize,
    pub average_memory_usage: usize,
    pub memory_samples: Vec<MemorySample>,
}

/// å†…å­˜é‡‡æ ·
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MemorySample {
    pub timestamp: std::time::SystemTime,
    pub memory_usage: usize,
    pub phase: String,
}

impl BuildPerformanceMonitor {
    /// åˆ›å»ºæ–°çš„æ€§èƒ½ç›‘æ§å™¨
    pub fn new(enabled: bool) -> Self {
        Self {
            metrics: BuildMetrics::new(),
            phase_timers: HashMap::new(),
            enabled,
        }
    }

    /// å¼€å§‹ç›‘æ§æ„å»ºé˜¶æ®µ
    pub fn start_phase(&mut self, phase_name: &str) {
        if !self.enabled {
            return;
        }

        self.phase_timers.insert(phase_name.to_string(), Instant::now());

        // è®°å½•å†…å­˜ä½¿ç”¨æƒ…å†µ
        if let Ok(memory_usage) = self.get_current_memory_usage() {
            self.metrics.memory_usage.memory_samples.push(MemorySample {
                timestamp: std::time::SystemTime::now(),
                memory_usage,
                phase: phase_name.to_string(),
            });
        }
    }

    /// ç»“æŸç›‘æ§æ„å»ºé˜¶æ®µ
    pub fn end_phase(&mut self, phase_name: &str) {
        if !self.enabled {
            return;
        }

        if let Some(start_time) = self.phase_timers.remove(phase_name) {
            let duration = start_time.elapsed();
            self.metrics.phase_timings.insert(phase_name.to_string(), duration);

            // æ›´æ–°ç‰¹å®šé˜¶æ®µçš„æ—¶é—´
            match phase_name {
                "compilation" => self.metrics.compilation_time = duration,
                "optimization" => self.metrics.optimization_time = duration,
                "io" => self.metrics.io_time = duration,
                "cache" => self.metrics.cache_time = duration,
                _ => {}
            }
        }
    }

    /// è®°å½•æ–‡ä»¶å¤„ç†æ—¶é—´
    pub fn record_file_timing(&mut self, file_path: &str, duration: Duration) {
        if !self.enabled {
            return;
        }

        self.metrics.file_timings.insert(file_path.to_string(), duration);
    }

    /// è®°å½•ç¼“å­˜å‘½ä¸­
    pub fn record_cache_hit(&mut self) {
        if !self.enabled {
            return;
        }

        self.metrics.cache_hits += 1;
        self.update_cache_hit_ratio();
    }

    /// è®°å½•ç¼“å­˜æœªå‘½ä¸­
    pub fn record_cache_miss(&mut self) {
        if !self.enabled {
            return;
        }

        self.metrics.cache_misses += 1;
        self.update_cache_hit_ratio();
    }

    /// æ›´æ–°ç¼“å­˜å‘½ä¸­ç‡
    fn update_cache_hit_ratio(&mut self) {
        let total = self.metrics.cache_hits + self.metrics.cache_misses;
        if total > 0 {
            self.metrics.cache_hit_ratio = self.metrics.cache_hits as f64 / total as f64;
        }
    }

    /// è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ
    fn get_current_memory_usage(&self) -> Result<usize, std::io::Error> {
        #[cfg(target_os = "macos")]
        {
            use std::process::Command;

            let output = Command::new("ps")
                .args(&["-o", "rss=", "-p", &std::process::id().to_string()])
                .output()?;

            let memory_kb = String::from_utf8_lossy(&output.stdout)
                .trim()
                .parse::<usize>()
                .unwrap_or(0);

            Ok(memory_kb * 1024) // è½¬æ¢ä¸ºå­—èŠ‚
        }

        #[cfg(not(target_os = "macos"))]
        {
            // å…¶ä»–å¹³å°çš„å®ç°
            Ok(0)
        }
    }

    /// ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    pub fn generate_report(&mut self) -> BuildPerformanceReport {
        if !self.enabled {
            return BuildPerformanceReport::empty();
        }

        // è®¡ç®—æ€»æ„å»ºæ—¶é—´
        self.metrics.total_build_time = self.metrics.phase_timings
            .values()
            .sum();

        // è®¡ç®—å‹ç¼©æ¯”
        if self.metrics.total_input_size > 0 {
            self.metrics.compression_ratio =
                (self.metrics.total_input_size - self.metrics.total_output_size) as f64 /
                self.metrics.total_input_size as f64;
        }

        // è®¡ç®—å†…å­˜ç»Ÿè®¡
        self.calculate_memory_stats();

        BuildPerformanceReport {
            metrics: self.metrics.clone(),
            recommendations: self.generate_recommendations(),
            bottlenecks: self.identify_bottlenecks(),
        }
    }

    /// è®¡ç®—å†…å­˜ç»Ÿè®¡
    fn calculate_memory_stats(&mut self) {
        if self.metrics.memory_usage.memory_samples.is_empty() {
            return;
        }

        let memory_values: Vec<usize> = self.metrics.memory_usage.memory_samples
            .iter()
            .map(|sample| sample.memory_usage)
            .collect();

        self.metrics.memory_usage.peak_memory_usage =
            *memory_values.iter().max().unwrap_or(&0);

        self.metrics.memory_usage.average_memory_usage =
            memory_values.iter().sum::<usize>() / memory_values.len();
    }

    /// ç”Ÿæˆä¼˜åŒ–å»ºè®®
    fn generate_recommendations(&self) -> Vec<String> {
        let mut recommendations = Vec::new();

        // ç¼“å­˜å‘½ä¸­ç‡å»ºè®®
        if self.metrics.cache_hit_ratio < 0.5 {
            recommendations.push(
                "ç¼“å­˜å‘½ä¸­ç‡è¾ƒä½ï¼Œè€ƒè™‘è°ƒæ•´ç¼“å­˜ç­–ç•¥æˆ–å¢åŠ ç¼“å­˜å¤§å°".to_string()
            );
        }

        // å¹¶è¡Œæ•ˆç‡å»ºè®®
        if self.metrics.parallel_efficiency < 0.7 {
            recommendations.push(
                "å¹¶è¡Œæ•ˆç‡è¾ƒä½ï¼Œè€ƒè™‘å‡å°‘çº¿ç¨‹æ•°æˆ–ä¼˜åŒ–ä»»åŠ¡åˆ†é…".to_string()
            );
        }

        // å†…å­˜ä½¿ç”¨å»ºè®®
        if self.metrics.memory_usage.peak_memory_usage > 1024 * 1024 * 1024 { // 1GB
            recommendations.push(
                "å†…å­˜ä½¿ç”¨é‡è¾ƒé«˜ï¼Œè€ƒè™‘å¯ç”¨æµå¼å¤„ç†æˆ–å‡å°‘å¹¶è¡Œåº¦".to_string()
            );
        }

        // ç¼–è¯‘æ—¶é—´å»ºè®®
        if self.metrics.compilation_time.as_millis() > 5000 {
            recommendations.push(
                "ç¼–è¯‘æ—¶é—´è¾ƒé•¿ï¼Œè€ƒè™‘å¯ç”¨å¢é‡ç¼–è¯‘æˆ–ä¼˜åŒ–ä»£ç ç»“æ„".to_string()
            );
        }

        recommendations
    }

    /// è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ
    fn identify_bottlenecks(&self) -> Vec<String> {
        let mut bottlenecks = Vec::new();

        // æ‰¾å‡ºæœ€è€—æ—¶çš„é˜¶æ®µ
        if let Some((phase, duration)) = self.metrics.phase_timings
            .iter()
            .max_by_key(|(_, duration)| *duration) {

            let percentage = duration.as_millis() as f64 /
                self.metrics.total_build_time.as_millis() as f64 * 100.0;

            if percentage > 50.0 {
                bottlenecks.push(format!(
                    "é˜¶æ®µ '{}' å ç”¨äº† {:.1}% çš„æ„å»ºæ—¶é—´",
                    phase, percentage
                ));
            }
        }

        // æ‰¾å‡ºæœ€è€—æ—¶çš„æ–‡ä»¶
        if let Some((file, duration)) = self.metrics.file_timings
            .iter()
            .max_by_key(|(_, duration)| *duration) {

            if duration.as_millis() > 1000 {
                bottlenecks.push(format!(
                    "æ–‡ä»¶ '{}' å¤„ç†æ—¶é—´è¿‡é•¿: {} ms",
                    file, duration.as_millis()
                ));
            }
        }

        bottlenecks
    }
}
```

## ğŸ”§ æ„å»ºå·¥å…·é…ç½®æœ€ä½³å®è·µ

### âœ… å¼€å‘ç¯å¢ƒä¼˜åŒ–
- [ ] å¯ç”¨å¢é‡ç¼–è¯‘å‡å°‘é‡å¤å·¥ä½œ
- [ ] ä½¿ç”¨é€‚åº¦çš„å¹¶è¡Œåº¦é¿å…èµ„æºç«äº‰
- [ ] å¯ç”¨ç¼“å­˜ä½†ä½¿ç”¨ä¿å®ˆç­–ç•¥
- [ ] ç¦ç”¨é‡åº¦ä¼˜åŒ–ä»¥æå‡æ„å»ºé€Ÿåº¦
- [ ] å¯ç”¨è¯¦ç»†æ—¥å¿—ä¾¿äºè°ƒè¯•

### âœ… ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–
- [ ] å¯ç”¨æ‰€æœ‰ä¼˜åŒ–é€‰é¡¹
- [ ] ä½¿ç”¨æ¿€è¿›çš„ç¼“å­˜ç­–ç•¥
- [ ] å¯ç”¨æ­»ä»£ç æ¶ˆé™¤
- [ ] å¯ç”¨ CSS å‹ç¼©å’Œæ··æ·†
- [ ] ç”Ÿæˆæ„å»ºæŠ¥å‘Šç”¨äºåˆ†æ

### âœ… æ€§èƒ½ç›‘æ§
- [ ] å®šæœŸåˆ†ææ„å»ºæ€§èƒ½æŠ¥å‘Š
- [ ] ç›‘æ§ç¼“å­˜å‘½ä¸­ç‡
- [ ] è·Ÿè¸ªæ„å»ºæ—¶é—´è¶‹åŠ¿
- [ ] è¯†åˆ«å’Œä¼˜åŒ–æ€§èƒ½ç“¶é¢ˆ
- [ ] è°ƒæ•´å¹¶è¡Œåº¦å’Œå†…å­˜ä½¿ç”¨

### âœ… ç¼“å­˜ç®¡ç†
- [ ] æ ¹æ®é¡¹ç›®è§„æ¨¡é€‰æ‹©åˆé€‚çš„ç¼“å­˜ç­–ç•¥
- [ ] å®šæœŸæ¸…ç†è¿‡æœŸç¼“å­˜
- [ ] ç›‘æ§ç¼“å­˜å¤§å°å’Œå‘½ä¸­ç‡
- [ ] é…ç½®åˆç†çš„ TTL æ—¶é—´
- [ ] ä½¿ç”¨ä¾èµ–è·Ÿè¸ªç¡®ä¿ç¼“å­˜ä¸€è‡´æ€§

é€šè¿‡åˆç†çš„æ„å»ºå·¥å…·ä¼˜åŒ–ï¼Œæ‚¨å¯ä»¥æ˜¾è‘—æå‡ CSS-in-Rust é¡¹ç›®çš„æ„å»ºæ€§èƒ½å’Œå¼€å‘ä½“éªŒï¼ğŸš€
